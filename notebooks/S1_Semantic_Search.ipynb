{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07d2a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from datasets import Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a92d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_knowledge_base(json_file_paths):\n",
    "    \"\"\"\n",
    "    Loads data from a list of JSON files and flattens it into a list of Q&A objects.\n",
    "    Each Q&A object will contain:\n",
    "    - 'question': The question string\n",
    "    - 'answer': The answer string\n",
    "    - 'id': The ID of the Q&A pair\n",
    "    - 'intent': The intent of the question\n",
    "    - 'type': The type of the question/answer\n",
    "    - 'source_file': The filename it came from (for debugging/info)\n",
    "    \"\"\"\n",
    "    knowledge_base = []\n",
    "    for file_path in json_file_paths:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "                for category, items in data.items():\n",
    "                    for item in items:\n",
    "                        knowledge_base.append({\n",
    "                            'question': item['question'],\n",
    "                            'answer': item['answer'],\n",
    "                            'id': item['id'],\n",
    "                            'intent': item.get('intent', 'N/A'),\n",
    "                            'type': item.get('type', 'N/A'),\n",
    "                            'related_topics': item.get('related_topics', []),\n",
    "                            'source_file': os.path.basename(file_path)\n",
    "                        })\n",
    "            print(f\"Successfully loaded {len(data)} categories from {os.path.basename(file_path)}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: JSON file not found at {file_path}. Please ensure it's in the correct directory. Skipping.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(f\"Error: Could not decode JSON from {file_path}. Check for syntax errors. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred while loading {file_path}: {e}\")\n",
    "    return knowledge_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2822226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading knowledge base for fine-tuning...\n",
      "Successfully loaded 8 categories from A01_2021.json\n",
      "Successfully loaded 8 categories from A02_2021.json\n",
      "Successfully loaded 8 categories from A03_2021.json\n",
      "Successfully loaded 8 categories from A04_2021.json\n",
      "Successfully loaded 8 categories from A05_2021.json\n",
      "Successfully loaded 8 categories from A06_2021.json\n",
      "Successfully loaded 8 categories from A07_2021.json\n",
      "Successfully loaded 8 categories from A08_2021.json\n",
      "Successfully loaded 8 categories from A09_2021.json\n",
      "Successfully loaded 8 categories from A10_2021.json\n",
      "Prepared 3398 training examples.\n",
      "Prepared 378 validation queries and 378 validation corpus entries.\n"
     ]
    }
   ],
   "source": [
    "json_file_paths = [\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A01_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A02_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A03_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A04_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A05_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A06_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A07_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A08_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A09_2021.json',\n",
    "    r'D:\\OWASP_BERT\\QA_Pairs\\Enhanced_QA\\A10_2021.json',\n",
    "]\n",
    "\n",
    "print(\"Loading knowledge base for fine-tuning...\")\n",
    "kb_data = load_knowledge_base(json_file_paths)\n",
    "\n",
    "if not kb_data:\n",
    "    raise ValueError(\"Knowledge base is empty. Cannot fine-tune without data. Please check your JSON files and paths.\")\n",
    "\n",
    "train_kb_data, val_kb_data = train_test_split(kb_data, test_size=0.1, random_state=42)\n",
    "\n",
    "\n",
    "train_examples = []\n",
    "for item in train_kb_data:\n",
    "    train_examples.append(InputExample(texts=[item['question'], item['answer']]))\n",
    "\n",
    "print(f\"Prepared {len(train_examples)} training examples.\")\n",
    "\n",
    "\n",
    "eval_queries = {}\n",
    "eval_corpus = {}\n",
    "eval_relevant_docs = {}\n",
    "\n",
    "answer_id_counter = 0\n",
    "answer_id_map = {}\n",
    "\n",
    "for item in val_kb_data:\n",
    "    query_id = item['id']\n",
    "    query_text = item['question']\n",
    "\n",
    "    if item['answer'] not in answer_id_map:\n",
    "        answer_id_map[item['answer']] = f\"ans_{answer_id_counter}\"\n",
    "        answer_id_counter += 1\n",
    "    corpus_id = answer_id_map[item['answer']]\n",
    "    corpus_text = item['answer']\n",
    "\n",
    "    eval_queries[query_id] = query_text\n",
    "    eval_corpus[corpus_id] = corpus_text\n",
    "\n",
    "    if query_id not in eval_relevant_docs:\n",
    "        eval_relevant_docs[query_id] = set()\n",
    "    eval_relevant_docs[query_id].add(corpus_id)\n",
    "\n",
    "print(f\"Prepared {len(eval_queries)} validation queries and {len(eval_corpus)} validation corpus entries.\")\n",
    "\n",
    "# Create DataLoader for training\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32) # Batch size for GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9bf6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing base SentenceTransformer model 'all-mpnet-base-v2' for fine-tuning...\n",
      "Base model initialized.\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Initialize the base BERT model and define the loss function\n",
    "\n",
    "print(\"Initializing base SentenceTransformer model 'all-mpnet-base-v2' for fine-tuning...\")\n",
    "model = SentenceTransformer('all-mpnet-base-v2') # Changed base model for higher performance\n",
    "print(\"Base model initialized.\")\n",
    "\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6317472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting advanced fine-tuning for 10 epochs...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6296ea8c3de444c1a767eb168f443593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1070' max='1070' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1070/1070 4:40:50, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Owasp Validation Cosine Accuracy@1</th>\n",
       "      <th>Owasp Validation Cosine Accuracy@3</th>\n",
       "      <th>Owasp Validation Cosine Accuracy@5</th>\n",
       "      <th>Owasp Validation Cosine Accuracy@10</th>\n",
       "      <th>Owasp Validation Cosine Precision@1</th>\n",
       "      <th>Owasp Validation Cosine Precision@3</th>\n",
       "      <th>Owasp Validation Cosine Precision@5</th>\n",
       "      <th>Owasp Validation Cosine Precision@10</th>\n",
       "      <th>Owasp Validation Cosine Recall@1</th>\n",
       "      <th>Owasp Validation Cosine Recall@3</th>\n",
       "      <th>Owasp Validation Cosine Recall@5</th>\n",
       "      <th>Owasp Validation Cosine Recall@10</th>\n",
       "      <th>Owasp Validation Cosine Ndcg@10</th>\n",
       "      <th>Owasp Validation Cosine Mrr@10</th>\n",
       "      <th>Owasp Validation Cosine Map@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.330688</td>\n",
       "      <td>0.199471</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957710</td>\n",
       "      <td>0.943122</td>\n",
       "      <td>0.943122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.329806</td>\n",
       "      <td>0.198942</td>\n",
       "      <td>0.099735</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.989418</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>0.959726</td>\n",
       "      <td>0.946649</td>\n",
       "      <td>0.946838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>321</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.332451</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.965518</td>\n",
       "      <td>0.953483</td>\n",
       "      <td>0.953483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>428</td>\n",
       "      <td>No log</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.910053</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963665</td>\n",
       "      <td>0.951058</td>\n",
       "      <td>0.951058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>535</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.332451</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968101</td>\n",
       "      <td>0.957011</td>\n",
       "      <td>0.957011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>642</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968431</td>\n",
       "      <td>0.957540</td>\n",
       "      <td>0.957540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>749</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.330688</td>\n",
       "      <td>0.199471</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.992063</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968397</td>\n",
       "      <td>0.957540</td>\n",
       "      <td>0.957540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>856</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.199471</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>0.997354</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967374</td>\n",
       "      <td>0.956129</td>\n",
       "      <td>0.956129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>963</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.968148</td>\n",
       "      <td>0.957099</td>\n",
       "      <td>0.957099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "      <td>No Log</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1070</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.331570</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.923280</td>\n",
       "      <td>0.994709</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969124</td>\n",
       "      <td>0.958422</td>\n",
       "      <td>0.958422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3272462edc15425ebc377cce55e29e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d723c098750943f2b6b64e7e4f7c834c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.32s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5974adce6b2b4829b9e61e8a4a22bc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0da16d2daa9436d8876392f7d7e7edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.34s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d89825fe332f4d06bc3dacc58555f4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4de349fd7c44b3bbc8489323191435f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.43s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d66c01e66e942a3b8712cce5c7328fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b381cd734d452fadabd9502c8c1eeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.39s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b8341635eaf4f54b4ab447348fcb36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ddb8a4c17e04ca194b91899bc535f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.57s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4419f0c70e8440fd89f5b4758ebd32c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bed167f721423a96dfb2408abfaa91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.47s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3166a0c5619c4a5f9de8f68b3930b7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ca6139ea7543ed9cc76319047064df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.51s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0058bebf8be42caade0f75760c0b9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e71418afdaa47e492975339f2509c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.41s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0429d612b4094e8781bbc20e621d11be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "463ab4533b6a4264a4396ab1cb89f9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.46s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f20d93048284ca6a5bda5239fd3b349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637a1563d0344b62bf0c89fbd5f0a01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corpus Chunks: 100%|██████████| 1/1 [00:21<00:00, 21.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Advanced fine-tuning complete!\n",
      "Best fine-tuned model saved to: ./fine_tuned_owasp_model_advanced/best_model\n"
     ]
    }
   ],
   "source": [
    "# Define training parameters\n",
    "num_epochs = 10  # Number of training epochs. Adjust based on dataset size and performance.\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) # 10% of total training steps\n",
    "output_path = './fine_tuned_owasp_model_advanced' # Directory to save the fine-tuned model\n",
    "model_save_name = 'best_model' # Name for the best model subdirectory (within output_path)\n",
    "\n",
    "print(f\"Starting advanced fine-tuning for {num_epochs} epochs...\")\n",
    "\n",
    "# Create the InformationRetrievalEvaluator\n",
    "# This evaluator calculates metrics like Average Precision, Recall@k during training\n",
    "# and saves the model that achieves the best score on the specified metric.\n",
    "ir_evaluator = evaluation.InformationRetrievalEvaluator(\n",
    "    queries=eval_queries,\n",
    "    corpus=eval_corpus,\n",
    "    relevant_docs=eval_relevant_docs,\n",
    "    show_progress_bar=True,\n",
    "    corpus_chunk_size=500, # Adjust based on GPU memory. Larger chunk_size uses more memory but might be faster.\n",
    "    name='owasp_validation' # Name for the evaluation log\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "# The evaluator will be called periodically (every 10% of an epoch by default)\n",
    "# and the best model based on the evaluator's score will be saved.\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
    "          evaluator=ir_evaluator,\n",
    "          epochs=num_epochs,\n",
    "          warmup_steps=warmup_steps,\n",
    "          output_path=output_path,\n",
    "          save_best_model=True, # Save the model that achieves the best performance on the evaluator\n",
    "          optimizer_params={'lr': 2e-5}, # Learning rate (common starting point)\n",
    "          use_amp=True, # Use Automatic Mixed Precision for faster training on GPUs\n",
    "          checkpoint_path=output_path, # Path to save checkpoints\n",
    "          checkpoint_save_steps=len(train_dataloader) // 2, # Save checkpoint after half of an epoch (adjust as needed)\n",
    "          checkpoint_save_total_limit=3 # Keep only the last 3 checkpoints\n",
    "         )\n",
    "\n",
    "print(\"\\nAdvanced fine-tuning complete!\")\n",
    "print(f\"Best fine-tuned model saved to: {output_path}/{model_save_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75430309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attempting to load model from: ./fine_tuned_owasp_model_advanced\n",
      "Checking if './fine_tuned_owasp_model_advanced' directory exists: True\n",
      "Contents of './fine_tuned_owasp_model_advanced': ['1_Pooling', '2_Normalize', 'checkpoint-1007', 'checkpoint-1060', 'checkpoint-1070', 'config.json', 'config_sentence_transformers.json', 'eval', 'model.safetensors', 'modules.json', 'README.md', 'sentence_bert_config.json', 'special_tokens_map.json', 'tokenizer.json', 'tokenizer_config.json', 'vocab.txt']\n",
      "Fine-tuned model loaded successfully.\n",
      "\n",
      "Testing fine-tuned model with example embeddings:\n",
      "Similarity (Q1, A1): 0.8621 (Expected High)\n",
      "Similarity (Q2, A2): 0.5542 (Expected High)\n",
      "Similarity (Q1, A2): 0.1228 (Expected Low)\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Verify the fine-tuned model\n",
    "\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "output_path = './fine_tuned_owasp_model_advanced' # Directory where the model was saved\n",
    "\n",
    "# IMPORTANT CHANGE: The model components are directly in output_path,\n",
    "# not in a 'best_model' subdirectory in this case.\n",
    "full_model_path = output_path # We load directly from the output_path\n",
    "\n",
    "print(f\"\\nAttempting to load model from: {full_model_path}\")\n",
    "\n",
    "# --- Debugging Checks (confirming the path we are trying to load) ---\n",
    "print(f\"Checking if '{full_model_path}' directory exists: {os.path.exists(full_model_path)}\")\n",
    "if os.path.exists(full_model_path):\n",
    "    print(f\"Contents of '{full_model_path}': {os.listdir(full_model_path)}\")\n",
    "# --- End Debugging Checks ---\n",
    "\n",
    "if os.path.exists(full_model_path):\n",
    "    try:\n",
    "        # Load the fine-tuned model directly from the output_path\n",
    "        best_fine_tuned_model = SentenceTransformer(full_model_path)\n",
    "        print(\"Fine-tuned model loaded successfully.\")\n",
    "\n",
    "        # Test with some example queries and answers\n",
    "        print(\"\\nTesting fine-tuned model with example embeddings:\")\n",
    "        test_question_1 = \"What is SQL Injection?\"\n",
    "        test_answer_1 = \"SQL injection is a web security vulnerability that allows an attacker to alter the SQL queries made by an application.\"\n",
    "\n",
    "        test_question_2 = \"Tell me about broken access control\"\n",
    "        test_answer_2 = \"Broken access control refers to a failure in enforcing policies that restrict users from acting outside their intended permissions.\"\n",
    "\n",
    "        test_embedding_q1 = best_fine_tuned_model.encode(test_question_1, convert_to_tensor=True)\n",
    "        test_embedding_a1 = best_fine_tuned_model.encode(test_answer_1, convert_to_tensor=True)\n",
    "\n",
    "        test_embedding_q2 = best_fine_tuned_model.encode(test_question_2, convert_to_tensor=True)\n",
    "        test_embedding_a2 = best_fine_tuned_model.encode(test_answer_2, convert_to_tensor=True)\n",
    "\n",
    "        # Calculate similarity between a question and its correct answer\n",
    "        similarity_q1_a1 = util.cos_sim(test_embedding_q1, test_embedding_a1).item()\n",
    "        similarity_q2_a2 = util.cos_sim(test_embedding_q2, test_embedding_a2).item()\n",
    "\n",
    "        # Calculate similarity between a question and an incorrect answer (e.g., Q1 with A2)\n",
    "        similarity_q1_a2 = util.cos_sim(test_embedding_q1, test_embedding_a2).item()\n",
    "\n",
    "        print(f\"Similarity (Q1, A1): {similarity_q1_a1:.4f} (Expected High)\")\n",
    "        print(f\"Similarity (Q2, A2): {similarity_q2_a2:.4f} (Expected High)\")\n",
    "        print(f\"Similarity (Q1, A2): {similarity_q1_a2:.4f} (Expected Low)\")\n",
    "\n",
    "        # If fine-tuning was successful, you should see higher scores for (Q, A) pairs\n",
    "        # and lower scores for (Q, incorrect A) pairs compared to the base model.\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during model loading or testing: {e}\")\n",
    "        print(\"This might indicate an issue with the saved model files, even though the directory exists.\")\n",
    "        print(\"Please review the output of Cell 5 for any errors or warnings during training.\")\n",
    "else:\n",
    "    print(f\"\\nError: Model directory '{full_model_path}' still not found or empty!\")\n",
    "    print(\"This indicates a fundamental issue with the saving process in Cell 5.\")\n",
    "    print(\"Please ensure Cell 5 ran to completion without errors and that enough disk space is available.\")\n",
    "    print(\"If using Google Colab, ensure the session hasn't disconnected or reset and try saving to /content/ drive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b47e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot-env",
   "language": "python",
   "name": "chatbot-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
